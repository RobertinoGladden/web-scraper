# Submission ETL Pipeline

## Project Overview
ETL Pipeline Sederhana untuk Scraping Data Fashion dari https://fashion-studio.dicoding.dev/.
- **Ekstraksi**: Mengambil data dari 50 halaman di https://fashion-studio.dicoding.dev/ dengan kolom Title, Price, Rating, Colors, Size, Gender, timestamp, dan page_number. Data awal yang di-scrape lebih dari 1000 record.
- **Transformasi**: Membersihkan data dengan langkah berikut:
  - Mengonversi Price dari USD ke IDR (1 USD = Rp16.000).
  - Mengubah Rating menjadi tipe float (contoh: "4.5 / 5" menjadi 4.5, nilai invalid menjadi 0.0).
  - Mengubah Colors menjadi integer (contoh: "3 Colors" menjadi 3).
  - Menghapus teks "Size: " dan "Gender: " dari kolom Size dan Gender.
  - Menghapus data dengan nilai null, duplikat, atau invalid (seperti "Unknown Product", Price <= 0, Colors <= 0, Size/Gender kosong).
  - Memastikan tipe data: Price (float), Rating (float), Colors (int), Size (str), Gender (str), timestamp (str), page_number (int).
  - Data setelah transformasi: 867 record.
- **Loading**: Menyimpan data ke dua repositori:
  - Flat file: `products.csv`.
  - Google Sheets: `ETL_Pipeline_Results` dengan akses "Anyone with the link" sebagai editor.
- **Unit Test**: Disimpan di folder `tests` dengan coverage 94%. Total 28 test case: 27 lulus, 1 gagal (detail di bawah).

## Project Structure
Berikut adalah struktur proyek yang digunakan:
DICODING ETL PIPELINE SEDERHANA
```bash
├── tests
│   ├── test_extract.py
│   ├── test_transform.py
│   └── test_load.py
├── utils
│   ├── extract.py
│   ├── transform.py
│   └── load.py
├── main.py
├── requirements.txt
├── submission.txt
├── products.csv
├── google-sheets-api.json
```
## Dependencies
Semua dependencies yang diperlukan tercantum dalam `requirements.txt`. Pastikan untuk menginstall dependencies sebelum menjalankan pipeline dengan perintah:
```bash
pip install -r requirements.txt
```
Dependencies yang digunakan meliputi:
- pandas
- requests
- beautifulsoup4
- gspread
- google-auth

## Instructions to Run from ZIP File
1. **Extract ZIP File**:
   - Ekstrak file ZIP (`DICODING ETL PIPELINE SEDERHANA.zip`) ke direktori lokal Anda menggunakan perintah atau GUI (misalnya, dengan WinRAR atau `unzip submission-etl-pipeline.zip` di terminal).
2. **Navigate to Project Directory**:
   - Buka terminal dan navigasikan ke direktori yang diekstrak:
   - cd DICODING ETL PIPELINE SEDERHANA

3. **Install Dependencies**:
- Instal semua dependencies yang diperlukan:
``` bash
pip install -r requirements.txt
```
- Pastikan file `google-sheets-api.json` ada di root directory untuk autentikasi Google Sheets API.
4. **Run ETL Pipeline**:
- Jalankan pipeline dengan perintah:
```bash
python main.py
```
- Skrip akan mengekstrak data, mentransformasi, dan menyimpan hasil ke `products.csv` dan Google Sheets (`ETL_Pipeline_Results`).

## Instructions for Running Test Coverage from Start to Finish
1. **Navigate to Project Directory**:
- Pastikan Anda berada di direktori root proyek:
```bash
cd DICODING ETL PIPELINE SEDERHANA
```
2. **Install Dependencies** (jika belum):
- Instal dependencies:
```bash
pip install -r requirements.txt
```
- Pastikan `pytest`, `pytest-cov`, dan library lain yang diperlukan sudah terinstal.
3. **Run Unit Tests**:
- Jalankan semua test di folder `tests`:
```bash
pytest tests
```
- Ini akan menjalankan 28 test case dan menampilkan hasil (27 lulus, 1 gagal).
4. **Run Test Coverage**:
- Jalankan perintah berikut untuk mendapatkan laporan coverage:
```bash
pytest --cov=utils tests/ --cov-report term-missing
```
- Hasil akan menampilkan coverage untuk setiap file di `utils`.

## Test Coverage Results
Berikut adalah hasil test coverage berdasarkan perintah `pytest --cov=utils tests/ --cov-report term-missing`:
```bash 
Name                 Stmts   Miss  Cover   Missing
--------------------------------------------------
utils\__init__.py        0      0   100%
utils\extract.py        80      9    89%   55-57, 93-95, 112-114
utils\load.py           61      0   100%
utils\transform.py      52      2    96%   62-63
--------------------------------------------------
TOTAL                  193     11    94%
```
## URL Google Sheets
Hasil data disimpan di Google Sheets dengan nama `ETL_Pipeline_Results`. URL-nya adalah:
https://docs.google.com/spreadsheets/d/1MODv4lmOuj0bQKbKXh3eM6ZGH-QRrfBrdMsFyVcOmHQ/edit?gid=0#gid=0

Akses telah diberikan sebagai "Anyone with the link" dengan peran editor.